<section id="call" class=>
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading">Call for Papers</h2>
      </div>
    </div>

    <div class="text-center">
      <h3>Themes and Topics</h3>
    </div>

    <div class="row text-justify">
      <div class="col-md-12">
        <p class="large text-muted">
          Given the rapid advancement of LLMs, we present examples of topics we encourage authors to explore in this workshop:
        </p>

        <ul class="large text-muted">
          <li><b>Predicting the performance of LLM-based retrievers/re-rankers, or generative AI systems.</b> Most QPP studies still focus on predicting the performance of rankers based on small-scale pre-trained language models (e.g., BERT  or T5). However, little work has explored predicting the performance of newly emerged LLM-based retrievers/re-rankers , or more broadly, LLM-based generative AI systems. Therefore, we aim to ad- dress questions including, but not limited to, the following:</li>
            <ul class="large text-muted">
            <li> To what extent does the performance of existing QPP methods (designed for retrievers/re-rankers using small-scale pre-trained languages) generalise to LLM-based retrievers and re-rankers?</li>
            <li> How can we effectively predict the performance of emerging new re-ranking paradigms based on LLMs, such as pair-wise or list-wise re-rankers?</li>
            <li> How can we predict the performance of generative AI systems? E.g., how to predict the text generation quality of an LLM in response to a prompt? </li>
        </ul>
        </ul>

        <ul class="large text-muted">
          <li><b>Leveraging the capabilities of LLMs to enhance QPP quality.</b> LLMs have been applied to a wide range of natural language processing (NLP) and IR tasks, achieving numerous state-of-the-art results. However, few studies (e.g., <a href="https://arxiv.org/abs/2404.01012">QPP-GenRE</a>) have explored leveraging LLM to model QPP. We aim to address questions including, but not limited to, the following:</li>
            <ul class="large text-muted">
            <li> What kind of features from LLMs (e.g., embedding) can we use for QPP?</li>
            <li> How well a QPP model based on LLMs performs when predicting the ranking quality of an LLM-based retriever/re-ranker or the text generation quality of an LLM?</li>
        </ul>
        </ul>


        <ul class="large text-muted">
          <li><b>Applying QPP to benefit various downstream tasks.</b> Most studies evaluate QPP methods only using metrics not directly correlated to downstream tasks, e.g., linear correlation coefficients. However, it is under-explored whether QPP methods evaluated in such a way can be effectively applied to benefit downstream tasks, especially when it comes to applying them to important tasks in the era of LLMs, e.g., retrieval-augmented generation (RAG). So we aim to address questions including, but not limited to, the following:</b> </li>
            <ul class="large text-muted">
            <li> Which downstream tasks (especially in the era of LLMs) does QPP have the potential to benefit? E.g., in RAG, can QPP be used to determine when to rely on the retrieved documents? In LLM-based re-ranking, can QPP be used to determine <a href="https://dl.acm.org/doi/10.1145/3626772.3657864">query-specific re-ranking depths</a>?</li>
            <li> How exactly to use QPP to benefit those tasks?</li>
        </ul>
        </ul>


        <ul class="large text-muted">
          <li><b>Exploring QPP in the context of multi-modal content.</b> Most studies focus on QPP in the context of text. However, research on QPP in the context of multi-modal content, such as images or even video, remains limited. We aim to address questions including, but not limited to, the following:</b> </li>
            <ul class="large text-muted">
            <li> QPP for text-to-image search, image-to-image search, or image generation.</li>
            <li> QPP in the context of video search/generation.</li>
        </ul>
        </ul>

        <ul class="large text-muted">
          <li><b>Exploring multilingual QPP.</b> There’s limited research on QPP for languages other than English. How well do current QPP methods generalise to non-English languages?</b> </li>
        </ul>

        <p class="large text-muted">
          Beyond the above aspects, we also welcome submissions on other QPP-related aspects. There is a need for deeper exploration in other QPP-related areas, including, but not limited to, the following: QPP for conversational search, recommendation systems, question answering, and fairness. We aim to stimulate discussions on these topics.
        </p>

    <div class="text-center">
      <h3>Paper type</h3>
    </div>
    <div class="row text-justify">
      <div class="col-md-12">
        <p class="large text-muted">
        We welcome manuscripts about any QPP-related subjects. We welcome a diverse range of submission types:
        </p>

        <ul class="large text-muted">
          <li><b>Original papers.</b> We welcome paper submissions in various types, including research papers, position papers, reproducibility papers, survey papers, and data collection papers. All submissions should be ranged from 4 to 10 pages in length, including references. </li>
        </ul>

        <ul class="large text-muted">
          <li><b>Published papers.</b> We welcome papers already accepted at top-tier conferences or in journals, e.g., SIGIR, CIKM, WWW, ECIR, ACL, EMNLP, TOIS, IP&M. Authors should submit 1-page abstract for a published paper, including the full reference where the paper was accepted.</li>
        </ul>

      </div>
    </div>


    <div class="text-center">
      <h3>Paper submission & selection</h3>
    </div>
    <div class="row text-justify">
      <div class="col-md-12">

        <p class="large text-muted">
          Note that submissions be written in English.
          For original papers, double submission is not allowed except for papers already on ArXiv.
         <br><br>
         The papers (.pdf format) should be submitted using the EasyChair submission system at <a href="https://easychair.org/conferences/?conf=qpp2025">https://easychair.org/conferences/?conf=qpp2025</a>.
         The paper template can be found at <a href="https://ceur-ws.org/HOWTOSUBMIT.html">https://ceur-ws.org/HOWTOSUBMIT.html</a>.
         <br><br>
         The review process is single-blind. Each manuscript will be peer-reviewed by at least three programme committee (PC) members.
         <br><br>
         Authors of accepted papers will be invited to give oral presentations at the workshop.
         The accepted papers will be published in the CEUR-WS.org proceedings series.
          Since the proceedings only accept papers with a minimum of 4 pages, we will combine 1-page abstract submissions into one or more papers for publication.
        </p>
      </div>
    </div>

    <div class="text-center">
	<h3>Extension on TOIS Special Issue</h3>
   </div>
    <div class="row text-justify">
	<div class="col-md-12">
		<p class="large text-muted">
		The best papers submitted to the QPP++ 2025 workshop will be invited for an extension on the TOIS Special Issue on <a href=https://dl.acm.org/pb-assets/static_journal_pages/tois/pdf/ACM_TOIS_SI_QPPTNIRP-1719515704.pdf> "Query Performance Prediction Towards Novel Infoformation Retrieval Paradigms" </a>.
         The authors of the best papers are invited to implement suggestions and comments provided by the other participants to the workshop and submit an extended version of their work that will be published on the Transactions on Information Systems (TOIS).
		</p>
	</div>
  </div>

    <div class="text-center">
      <h3>Recommended benchmarks & tools</h3>
    </div>
    <div class="row text-justify">
      <div class="col-md-12">

        <p class="large text-muted">
         To facilitate workshop discussions, we encourage (though it is not mandatory) authors to use common, publicly available benchmarks. This will help authors share their experimental experiences and insights more effectively. We also plan to set a discussion session for sharing experience on common datasets
        </p>
        <ul class="large text-muted">
          <li><b>Text-based ad-hoc search:</b>  <a href="https://microsoft.github.io/msmarco/TREC-Deep-Learning.html">TREC-DL 19–23</a> and <a href="https://github.com/grill-lab/DL-Hard/">DL-Hard</a> based on MS MARCO V1 or V2 collections. </li>
        </ul>

        <ul class="large text-muted">
          <li><b>Text-based conversational search:</b> <a href="https://www.treccast.ai/">CAsT 19–22</a> and <a href="https://www.trecikat.com/">iKAT 23-24</a>.</li>
        </ul>

        <ul class="large text-muted">
          <li><b>Image search:</b> <a href="https://dl.acm.org/doi/10.1145/3539618.3591901">iQPP</a>.</li>
        </ul>

        <p class="large text-muted">
         We also recommend open-source implementations of QPP methods:
        </p>

         <ul class="large text-muted">
          <li> <a href="https://github.com/ChuanMeng/QPP4CS">QPP4CS (Python & Pytorch)</a>
         </li>

         <ul class="large text-muted">
          <li> <a href="https://github.com/ChuanMeng/QPP-GenRE">QPP-GenRE (Python & Pytorch)</a>
         </li>

         <ul class="large text-muted">
          <li> <a href="https://github.com/Zendelo/QPP-EnhancedEval">QPP-EnhancedEval (Python)</a>
         </li>

        <ul class="large text-muted">
          <li> <a href="https://github.com/gdebasis/qpp-eval">qpp-eval (Java)</a>
         </li>
        </ul>

      </div>
    </div>

    </div>


</section>